diff --git a/include/linux/mm_inline.h b/include/linux/mm_inline.h
index f6a2b2d20..df3d849f0 100644
--- a/include/linux/mm_inline.h
+++ b/include/linux/mm_inline.h
@@ -161,9 +161,9 @@ static inline int folio_lru_gen(const struct folio *folio)
 	return ((flags & LRU_GEN_MASK) >> LRU_GEN_PGOFF) - 1;
 }
 
-static inline bool lru_gen_is_active(const struct lruvec *lruvec, int gen)
+static inline bool lru_gen_is_active(const struct lruvec *lruvec, int gen, int type)
 {
-	unsigned long max_seq = lruvec->lrugen.max_seq;
+	unsigned long max_seq = lruvec->lrugen.max_seq[type];
 
 	VM_WARN_ON_ONCE(gen >= MAX_NR_GENS);
 
@@ -193,7 +193,7 @@ static inline void lru_gen_update_size(struct lruvec *lruvec, struct folio *foli
 
 	/* addition */
 	if (old_gen < 0) {
-		if (lru_gen_is_active(lruvec, new_gen))
+		if (lru_gen_is_active(lruvec, new_gen,type))
 			lru += LRU_ACTIVE;
 		__update_lru_size(lruvec, lru, zone, delta);
 		return;
@@ -201,20 +201,20 @@ static inline void lru_gen_update_size(struct lruvec *lruvec, struct folio *foli
 
 	/* deletion */
 	if (new_gen < 0) {
-		if (lru_gen_is_active(lruvec, old_gen))
+		if (lru_gen_is_active(lruvec, old_gen,type))
 			lru += LRU_ACTIVE;
 		__update_lru_size(lruvec, lru, zone, -delta);
 		return;
 	}
 
 	/* promotion */
-	if (!lru_gen_is_active(lruvec, old_gen) && lru_gen_is_active(lruvec, new_gen)) {
+	if (!lru_gen_is_active(lruvec, old_gen,type) && lru_gen_is_active(lruvec, new_gen,type)) {
 		__update_lru_size(lruvec, lru, zone, -delta);
 		__update_lru_size(lruvec, lru + LRU_ACTIVE, zone, delta);
 	}
 
 	/* demotion requires isolation, e.g., lru_deactivate_fn() */
-	VM_WARN_ON_ONCE(lru_gen_is_active(lruvec, old_gen) && !lru_gen_is_active(lruvec, new_gen));
+	VM_WARN_ON_ONCE(lru_gen_is_active(lruvec, old_gen,type) && !lru_gen_is_active(lruvec, new_gen,type));
 }
 
 static inline unsigned long lru_gen_folio_seq(const struct lruvec *lruvec,
@@ -248,7 +248,7 @@ static inline unsigned long lru_gen_folio_seq(const struct lruvec *lruvec,
 	else
 		gen = MAX_NR_GENS - folio_test_workingset(folio);
 
-	return max(READ_ONCE(lrugen->max_seq) - gen + 1, READ_ONCE(lrugen->min_seq[type]));
+	return max(READ_ONCE(lrugen->max_seq[type]) - gen + 1, READ_ONCE(lrugen->min_seq[type]));
 }
 
 static inline bool lru_gen_add_folio(struct lruvec *lruvec, struct folio *folio, bool reclaiming)
@@ -293,7 +293,7 @@ static inline bool lru_gen_del_folio(struct lruvec *lruvec, struct folio *folio,
 	VM_WARN_ON_ONCE_FOLIO(folio_test_unevictable(folio), folio);
 
 	/* for folio_migrate_flags() */
-	flags = !reclaiming && lru_gen_is_active(lruvec, gen) ? BIT(PG_active) : 0;
+	flags = !reclaiming && lru_gen_is_active(lruvec, gen, folio_is_file_lru(folio)) ? BIT(PG_active) : 0;
 	flags = set_mask_bits(&folio->flags.f, LRU_GEN_MASK, flags);
 	gen = ((flags & LRU_GEN_MASK) >> LRU_GEN_PGOFF) - 1;
 
diff --git a/include/linux/mmzone.h b/include/linux/mmzone.h
index 7fb7331c5..c360282cd 100644
--- a/include/linux/mmzone.h
+++ b/include/linux/mmzone.h
@@ -489,11 +489,11 @@ enum {
  */
 struct lru_gen_folio {
 	/* the aging increments the youngest generation number */
-	unsigned long max_seq;
+	unsigned long max_seq[ANON_AND_FILE];
 	/* the eviction increments the oldest generation numbers */
 	unsigned long min_seq[ANON_AND_FILE];
 	/* the birth time of each generation in jiffies */
-	unsigned long timestamps[MAX_NR_GENS];
+	unsigned long timestamps[ANON_AND_FILE][MAX_NR_GENS];
 	/* the multi-gen LRU lists, lazily sorted on eviction */
 	struct list_head folios[MAX_NR_GENS][ANON_AND_FILE][MAX_NR_ZONES];
 	/* the multi-gen LRU sizes, eventually consistent */
@@ -507,6 +507,7 @@ struct lru_gen_folio {
 	/* can be modified without holding the LRU lock */
 	atomic_long_t evicted[NR_HIST_GENS][ANON_AND_FILE][MAX_NR_TIERS];
 	atomic_long_t refaulted[NR_HIST_GENS][ANON_AND_FILE][MAX_NR_TIERS];
+	unsigned long nr_scan[ANON_AND_FILE];
 	/* whether the multi-gen LRU is enabled */
 	bool enabled;
 	/* the memcg generation this lru_gen_folio belongs to */
@@ -530,7 +531,7 @@ enum {
 
 struct lru_gen_mm_state {
 	/* synced with max_seq after each iteration */
-	unsigned long seq;
+	unsigned long seq[ANON_AND_FILE];
 	/* where the current iteration continues after */
 	struct list_head *head;
 	/* where the last iteration ended before */
@@ -545,7 +546,8 @@ struct lru_gen_mm_walk {
 	/* the lruvec under reclaim */
 	struct lruvec *lruvec;
 	/* max_seq from lru_gen_folio: can be out of date */
-	unsigned long seq;
+	unsigned long seq[ANON_AND_FILE];
+	int aging_type;
 	/* the next address within an mm to scan */
 	unsigned long next_addr;
 	/* to batch promoted pages */
diff --git a/mm/vmscan.c b/mm/vmscan.c
index 9909cd64c..533ccacbb 100644
--- a/mm/vmscan.c
+++ b/mm/vmscan.c
@@ -2839,7 +2839,11 @@ static bool should_clear_pmd_young(void)
  ******************************************************************************/
 
 #define DEFINE_MAX_SEQ(lruvec)						\
-	unsigned long max_seq = READ_ONCE((lruvec)->lrugen.max_seq)
+	unsigned long max_seq[ANON_AND_FILE] = {			\
+		READ_ONCE((lruvec)->lrugen.max_seq[LRU_GEN_ANON]),	\
+		READ_ONCE((lruvec)->lrugen.max_seq[LRU_GEN_FILE]),	\
+	}
+
 
 #define DEFINE_MIN_SEQ(lruvec)						\
 	unsigned long min_seq[ANON_AND_FILE] = {			\
@@ -2900,9 +2904,9 @@ static int get_swappiness(struct lruvec *lruvec, struct scan_control *sc)
 	return sc_swappiness(sc, memcg);
 }
 
-static int get_nr_gens(struct lruvec *lruvec, int type)
+static inline int get_nr_gens(struct lruvec *lruvec, int type)
 {
-	return lruvec->lrugen.max_seq - lruvec->lrugen.min_seq[type] + 1;
+	return lruvec->lrugen.max_seq[type] - lruvec->lrugen.min_seq[type] + 1;
 }
 
 static bool __maybe_unused seq_is_valid(struct lruvec *lruvec)
@@ -3182,7 +3186,7 @@ static void reset_mm_stats(struct lru_gen_mm_walk *walk, bool last)
 
 	lockdep_assert_held(&get_mm_list(lruvec_memcg(lruvec))->lock);
 
-	hist = lru_hist_from_seq(walk->seq);
+	hist = lru_hist_from_seq(walk->seq[walk->aging_type]);
 
 	for (i = 0; i < NR_MM_STATS; i++) {
 		WRITE_ONCE(mm_state->stats[hist][i],
@@ -3191,7 +3195,7 @@ static void reset_mm_stats(struct lru_gen_mm_walk *walk, bool last)
 	}
 
 	if (NR_HIST_GENS > 1 && last) {
-		hist = lru_hist_from_seq(walk->seq + 1);
+		hist = lru_hist_from_seq(walk->seq[walk->aging_type] + 1);
 
 		for (i = 0; i < NR_MM_STATS; i++)
 			WRITE_ONCE(mm_state->stats[hist][i], 0);
@@ -3203,6 +3207,7 @@ static bool iterate_mm_list(struct lru_gen_mm_walk *walk, struct mm_struct **ite
 	bool first = false;
 	bool last = false;
 	struct mm_struct *mm = NULL;
+	int type = walk->aging_type;
 	struct lruvec *lruvec = walk->lruvec;
 	struct mem_cgroup *memcg = lruvec_memcg(lruvec);
 	struct lru_gen_mm_list *mm_list = get_mm_list(memcg);
@@ -3220,9 +3225,9 @@ static bool iterate_mm_list(struct lru_gen_mm_walk *walk, struct mm_struct **ite
 	 */
 	spin_lock(&mm_list->lock);
 
-	VM_WARN_ON_ONCE(mm_state->seq + 1 < walk->seq);
+	VM_WARN_ON_ONCE(mm_state->seq[type]+ 1 < walk->seq[type]);
 
-	if (walk->seq <= mm_state->seq)
+	if (walk->seq[type] <= mm_state->seq[type])
 		goto done;
 
 	if (!mm_state->head)
@@ -3234,7 +3239,7 @@ static bool iterate_mm_list(struct lru_gen_mm_walk *walk, struct mm_struct **ite
 	do {
 		mm_state->head = mm_state->head->next;
 		if (mm_state->head == &mm_list->fifo) {
-			WRITE_ONCE(mm_state->seq, mm_state->seq + 1);
+			WRITE_ONCE(mm_state->seq[type], mm_state->seq[type] + 1);
 			last = true;
 			break;
 		}
@@ -3252,7 +3257,7 @@ static bool iterate_mm_list(struct lru_gen_mm_walk *walk, struct mm_struct **ite
 	spin_unlock(&mm_list->lock);
 
 	if (mm && first)
-		reset_bloom_filter(mm_state, walk->seq + 1);
+		reset_bloom_filter(mm_state, walk->seq[type] + 1);
 
 	if (*iter)
 		mmput_async(*iter);
@@ -3262,7 +3267,7 @@ static bool iterate_mm_list(struct lru_gen_mm_walk *walk, struct mm_struct **ite
 	return last;
 }
 
-static bool iterate_mm_list_nowalk(struct lruvec *lruvec, unsigned long seq)
+static inline bool iterate_mm_list_nowalk(struct lruvec *lruvec, unsigned long seq,int type)
 {
 	bool success = false;
 	struct mem_cgroup *memcg = lruvec_memcg(lruvec);
@@ -3271,12 +3276,12 @@ static bool iterate_mm_list_nowalk(struct lruvec *lruvec, unsigned long seq)
 
 	spin_lock(&mm_list->lock);
 
-	VM_WARN_ON_ONCE(mm_state->seq + 1 < seq);
+	VM_WARN_ON_ONCE(mm_state->seq[type] + 1 < seq);
 
 	if (seq > mm_state->seq) {
 		mm_state->head = NULL;
 		mm_state->tail = NULL;
-		WRITE_ONCE(mm_state->seq, mm_state->seq + 1);
+		WRITE_ONCE(mm_state->seq[type], mm_state->seq[type] + 1);
 		success = true;
 	}
 
@@ -3338,7 +3343,7 @@ static void reset_ctrl_pos(struct lruvec *lruvec, int type, bool carryover)
 	int hist, tier;
 	struct lru_gen_folio *lrugen = &lruvec->lrugen;
 	bool clear = carryover ? NR_HIST_GENS == 1 : NR_HIST_GENS > 1;
-	unsigned long seq = carryover ? lrugen->min_seq[type] : lrugen->max_seq + 1;
+	unsigned long seq = carryover ? lrugen->min_seq[type] : lrugen->max_seq[type] + 1
 
 	lockdep_assert_held(&lruvec->lru_lock);
 
@@ -3474,7 +3479,7 @@ static void reset_batch_size(struct lru_gen_mm_walk *walk)
 		WRITE_ONCE(lrugen->nr_pages[gen][type][zone],
 			   lrugen->nr_pages[gen][type][zone] + delta);
 
-		if (lru_gen_is_active(lruvec, gen))
+		if (lru_gen_is_active(lruvec, gen,type))
 			lru += LRU_ACTIVE;
 		__update_lru_size(lruvec, lru, zone, delta);
 	}
@@ -3502,7 +3507,7 @@ static int should_skip_vma(unsigned long start, unsigned long end, struct mm_wal
 		return true;
 
 	if (vma_is_anonymous(vma))
-		return !walk->swappiness;
+		return walk->aging_type == LRU_GEN_FILE || !walk->swappiness;
 
 	if (WARN_ON_ONCE(!vma->vm_file || !vma->vm_file->f_mapping))
 		return true;
@@ -3512,7 +3517,11 @@ static int should_skip_vma(unsigned long start, unsigned long end, struct mm_wal
 		return true;
 
 	if (shmem_mapping(mapping))
-		return !walk->swappiness;
+		return walk->aging_type == LRU_GEN_FILE || !walk->swappiness;
+
+	if (walk->aging_type == LRU_GEN_ANON)
+		return true;
+
 
 	if (walk->swappiness > MAX_SWAPPINESS)
 		return true;
@@ -3663,7 +3672,7 @@ static bool walk_pte_range(pmd_t *pmd, unsigned long start, unsigned long end,
 	struct mem_cgroup *memcg = lruvec_memcg(walk->lruvec);
 	struct pglist_data *pgdat = lruvec_pgdat(walk->lruvec);
 	DEFINE_MAX_SEQ(walk->lruvec);
-	int gen = lru_gen_from_seq(max_seq);
+	int gen = lru_gen_from_seq(max_seq[walk->aging_type]);
 	pmd_t pmdval;
 
 	pte = pte_offset_map_rw_nolock(args->mm, pmd, start & PMD_MASK, &pmdval, &ptl);
@@ -3739,7 +3748,7 @@ static void walk_pmd_range_locked(pud_t *pud, unsigned long addr, struct vm_area
 	struct mem_cgroup *memcg = lruvec_memcg(walk->lruvec);
 	struct pglist_data *pgdat = lruvec_pgdat(walk->lruvec);
 	DEFINE_MAX_SEQ(walk->lruvec);
-	int gen = lru_gen_from_seq(max_seq);
+	int gen = lru_gen_from_seq(max_seq[walk->aging_type]);
 
 	VM_WARN_ON_ONCE(pud_leaf(*pud));
 
@@ -3868,7 +3877,7 @@ static void walk_pmd_range(pud_t *pud, unsigned long start, unsigned long end,
 			walk_pmd_range_locked(pud, addr, vma, args, bitmap, &first);
 		}
 
-		if (!walk->force_scan && !test_bloom_filter(mm_state, walk->seq, pmd + i))
+		if (!walk->force_scan && !test_bloom_filter(mm_state, walk->seq[walk->aging_type], pmd + i))
 			continue;
 
 		walk->mm_stats[MM_NONLEAF_FOUND]++;
@@ -3879,7 +3888,7 @@ static void walk_pmd_range(pud_t *pud, unsigned long start, unsigned long end,
 		walk->mm_stats[MM_NONLEAF_ADDED]++;
 
 		/* carry over to the next generation */
-		update_bloom_filter(mm_state, walk->seq + 1, pmd + i);
+		update_bloom_filter(mm_state, walk->seq[walk->aging_type] + 1, pmd + i);
 	}
 
 	walk_pmd_range_locked(pud, -1, vma, args, bitmap, &first);
@@ -3948,7 +3957,7 @@ static void walk_mm(struct mm_struct *mm, struct lru_gen_mm_walk *walk)
 		err = -EBUSY;
 
 		/* another thread might have called inc_max_seq() */
-		if (walk->seq != max_seq)
+		if (walk->seq[walk->aging_type] != max_seq[walk->aging_type])
 			break;
 
 		/* the caller might be holding the lock for write */
@@ -4065,7 +4074,7 @@ static bool try_to_inc_min_seq(struct lruvec *lruvec, int swappiness)
 
 	/* find the oldest populated generation */
 	for_each_evictable_type(type, swappiness) {
-		while (min_seq[type] + MIN_NR_GENS <= lrugen->max_seq) {
+		while (min_seq[type] + MIN_NR_GENS <= lrugen->max_seq[type]) {
 			gen = lru_gen_from_seq(min_seq[type]);
 
 			for (zone = 0; zone < MAX_NR_ZONES; zone++) {
@@ -4088,16 +4097,6 @@ static bool try_to_inc_min_seq(struct lruvec *lruvec, int swappiness)
 	if (!seq_inc_flag)
 		return success;
 
-	/* see the comment on lru_gen_folio */
-	if (swappiness && swappiness <= MAX_SWAPPINESS) {
-		unsigned long seq = lrugen->max_seq - MIN_NR_GENS;
-
-		if (min_seq[LRU_GEN_ANON] > seq && min_seq[LRU_GEN_FILE] < seq)
-			min_seq[LRU_GEN_ANON] = seq;
-		else if (min_seq[LRU_GEN_FILE] > seq && min_seq[LRU_GEN_ANON] < seq)
-			min_seq[LRU_GEN_FILE] = seq;
-	}
-
 	for_each_evictable_type(type, swappiness) {
 		if (min_seq[type] <= lrugen->min_seq[type])
 			continue;
@@ -4110,34 +4109,30 @@ static bool try_to_inc_min_seq(struct lruvec *lruvec, int swappiness)
 	return success;
 }
 
-static bool inc_max_seq(struct lruvec *lruvec, unsigned long seq, int swappiness)
+static bool inc_max_seq(struct lruvec *lruvec, unsigned long seq, int type)
 {
 	bool success;
 	int prev, next;
-	int type, zone;
+	int zone;
 	struct lru_gen_folio *lrugen = &lruvec->lrugen;
 restart:
-	if (seq < READ_ONCE(lrugen->max_seq))
+	if (seq < READ_ONCE(lrugen->max_seq[type]))
 		return false;
 
 	spin_lock_irq(&lruvec->lru_lock);
 
 	VM_WARN_ON_ONCE(!seq_is_valid(lruvec));
 
-	success = seq == lrugen->max_seq;
+	success = seq == lrugen->max_seq[type];
 	if (!success)
 		goto unlock;
+	if (get_nr_gens(lruvec, type) == MAX_NR_GENS) {
+		if (!inc_min_seq(lruvec, type, 1)) {
+			spin_unlock_irq(&lruvec->lru_lock);
+			cond_resched();
+			goto restart;
+		}
 
-	for (type = 0; type < ANON_AND_FILE; type++) {
-		if (get_nr_gens(lruvec, type) != MAX_NR_GENS)
-			continue;
-
-		if (inc_min_seq(lruvec, type, swappiness))
-			continue;
-
-		spin_unlock_irq(&lruvec->lru_lock);
-		cond_resched();
-		goto restart;
 	}
 
 	/*
@@ -4146,29 +4141,28 @@ static bool inc_max_seq(struct lruvec *lruvec, unsigned long seq, int swappiness
 	 * with min_seq[LRU_GEN_ANON] if swapping is constrained. And if they do
 	 * overlap, cold/hot inversion happens.
 	 */
-	prev = lru_gen_from_seq(lrugen->max_seq - 1);
-	next = lru_gen_from_seq(lrugen->max_seq + 1);
 
-	for (type = 0; type < ANON_AND_FILE; type++) {
-		for (zone = 0; zone < MAX_NR_ZONES; zone++) {
-			enum lru_list lru = type * LRU_INACTIVE_FILE;
-			long delta = lrugen->nr_pages[prev][type][zone] -
-				     lrugen->nr_pages[next][type][zone];
+	prev = lru_gen_from_seq(lrugen->max_seq[type] - 1);
+	next = lru_gen_from_seq(lrugen->max_seq[type] + 1);
 
-			if (!delta)
-				continue;
 
-			__update_lru_size(lruvec, lru, zone, delta);
-			__update_lru_size(lruvec, lru + LRU_ACTIVE, zone, -delta);
-		}
+	for (zone = 0; zone < MAX_NR_ZONES; zone++) {
+		enum lru_list lru = type * LRU_INACTIVE_FILE;
+		long delta = lrugen->nr_pages[prev][type][zone] -
+			     lrugen->nr_pages[next][type][zone];
+ 
+		if (!delta)
+			continue;
+		__update_lru_size(lruvec, lru, zone, delta);
+		__update_lru_size(lruvec, lru + LRU_ACTIVE, zone, -delta);
+
 	}
 
-	for (type = 0; type < ANON_AND_FILE; type++)
-		reset_ctrl_pos(lruvec, type, false);
+	reset_ctrl_pos(lruvec, type, false);
 
-	WRITE_ONCE(lrugen->timestamps[next], jiffies);
+	WRITE_ONCE(lrugen->timestamps[type][next], jiffies);
 	/* make sure preceding modifications appear */
-	smp_store_release(&lrugen->max_seq, lrugen->max_seq + 1);
+	smp_store_release(&lrugen->max_seq[type], lrugen->max_seq[type] + 1);
 unlock:
 	spin_unlock_irq(&lruvec->lru_lock);
 
@@ -4176,7 +4170,7 @@ static bool inc_max_seq(struct lruvec *lruvec, unsigned long seq, int swappiness
 }
 
 static bool try_to_inc_max_seq(struct lruvec *lruvec, unsigned long seq,
-			       int swappiness, bool force_scan)
+			       int type,int swappiness, bool force_scan)
 {
 	bool success;
 	struct lru_gen_mm_walk *walk;
@@ -4184,13 +4178,13 @@ static bool try_to_inc_max_seq(struct lruvec *lruvec, unsigned long seq,
 	struct lru_gen_folio *lrugen = &lruvec->lrugen;
 	struct lru_gen_mm_state *mm_state = get_mm_state(lruvec);
 
-	VM_WARN_ON_ONCE(seq > READ_ONCE(lrugen->max_seq));
+	VM_WARN_ON_ONCE(seq > READ_ONCE(lrugen->max_seq[type]));
 
 	if (!mm_state)
-		return inc_max_seq(lruvec, seq, swappiness);
+		return inc_max_seq(lruvec, seq, type);
 
 	/* see the comment in iterate_mm_list() */
-	if (seq <= READ_ONCE(mm_state->seq))
+	if (seq <= READ_ONCE(mm_state->seq[type]))
 		return false;
 
 	/*
@@ -4200,18 +4194,19 @@ static bool try_to_inc_max_seq(struct lruvec *lruvec, unsigned long seq,
 	 * is less efficient, but it avoids bursty page faults.
 	 */
 	if (!should_walk_mmu()) {
-		success = iterate_mm_list_nowalk(lruvec, seq);
+		success = iterate_mm_list_nowalk(lruvec, seq, type);
 		goto done;
 	}
 
 	walk = set_mm_walk(NULL, true);
 	if (!walk) {
-		success = iterate_mm_list_nowalk(lruvec, seq);
+		success = iterate_mm_list_nowalk(lruvec, seq, type);
 		goto done;
 	}
 
 	walk->lruvec = lruvec;
-	walk->seq = seq;
+	walk->aging_type = type;
+	walk->seq[type] = seq;
 	walk->swappiness = swappiness;
 	walk->force_scan = force_scan;
 
@@ -4222,7 +4217,7 @@ static bool try_to_inc_max_seq(struct lruvec *lruvec, unsigned long seq,
 	} while (mm);
 done:
 	if (success) {
-		success = inc_max_seq(lruvec, seq, swappiness);
+		success = inc_max_seq(lruvec, seq, type);
 		WARN_ON_ONCE(!success);
 	}
 
@@ -4272,7 +4267,7 @@ static bool lruvec_is_sizable(struct lruvec *lruvec, struct scan_control *sc)
 	for_each_evictable_type(type, swappiness) {
 		unsigned long seq;
 
-		for (seq = min_seq[type]; seq <= max_seq; seq++) {
+		for (seq = min_seq[type]; seq <= max_seq[type]; seq++) {
 			gen = lru_gen_from_seq(seq);
 
 			for (zone = 0; zone < MAX_NR_ZONES; zone++)
@@ -4287,8 +4282,8 @@ static bool lruvec_is_sizable(struct lruvec *lruvec, struct scan_control *sc)
 static bool lruvec_is_reclaimable(struct lruvec *lruvec, struct scan_control *sc,
 				  unsigned long min_ttl)
 {
-	int gen;
-	unsigned long birth;
+	int type, gen;
+	unsigned long birth = jiffies;
 	int swappiness = get_swappiness(lruvec, sc);
 	struct mem_cgroup *memcg = lruvec_memcg(lruvec);
 	DEFINE_MIN_SEQ(lruvec);
@@ -4299,8 +4294,14 @@ static bool lruvec_is_reclaimable(struct lruvec *lruvec, struct scan_control *sc
 	if (!lruvec_is_sizable(lruvec, sc))
 		return false;
 
-	gen = lru_gen_from_seq(evictable_min_seq(min_seq, swappiness));
-	birth = READ_ONCE(lruvec->lrugen.timestamps[gen]);
+	for_each_evictable_type(type, swappiness) {
+		unsigned long ts;
+
+		gen = lru_gen_from_seq(min_seq[type]);
+		ts = READ_ONCE(lruvec->lrugen.timestamps[type][gen]);
+		if (time_before(ts, birth))
+			birth = ts;
+	}
 
 	return time_is_before_jiffies(birth + min_ttl);
 }
@@ -4368,12 +4369,13 @@ bool lru_gen_look_around(struct page_vma_mapped_walk *pvmw)
 	unsigned long addr = pvmw->address;
 	struct vm_area_struct *vma = pvmw->vma;
 	struct folio *folio = pfn_folio(pvmw->pfn);
+	int ftype = folio_is_file_lru(folio);
 	struct mem_cgroup *memcg = folio_memcg(folio);
 	struct pglist_data *pgdat = folio_pgdat(folio);
 	struct lruvec *lruvec = mem_cgroup_lruvec(memcg, pgdat);
 	struct lru_gen_mm_state *mm_state = get_mm_state(lruvec);
 	DEFINE_MAX_SEQ(lruvec);
-	int gen = lru_gen_from_seq(max_seq);
+	int gen = lru_gen_from_seq(max_seq[ftype]);
 
 	lockdep_assert_held(pvmw->ptl);
 	VM_WARN_ON_ONCE_FOLIO(folio_test_lru(folio), folio);
@@ -4446,7 +4448,7 @@ bool lru_gen_look_around(struct page_vma_mapped_walk *pvmw)
 
 	/* feedback from rmap walkers to page table walkers */
 	if (mm_state && suitable_to_scan(i, young))
-		update_bloom_filter(mm_state, max_seq, pvmw->pmd);
+		update_bloom_filter(mm_state, max_seq[ftype], pvmw->pmd);
 
 	return true;
 }
@@ -4774,7 +4776,18 @@ static int scan_folios(unsigned long nr_to_scan, struct lruvec *lruvec,
 	 * There might not be eligible folios due to reclaim_idx. Check the
 	 * remaining to prevent livelock if it's not making progress.
 	 */
-	return isolated || !remaining ? scanned : 0;
+	if (isolated || !remaining) {
+		/* update scan counts for proportional type selection */
+		lrugen->nr_scan[type] += scanned;
+		if (lrugen->nr_scan[LRU_GEN_ANON] + lrugen->nr_scan[LRU_GEN_FILE] >
+		    MAX_LRU_BATCH * 64) {
+			lrugen->nr_scan[LRU_GEN_ANON] >>= 1;
+			lrugen->nr_scan[LRU_GEN_FILE] >>= 1;
+		}
+		return scanned;
+	}
+
+	return 0;
 }
 
 static int get_tier_idx(struct lruvec *lruvec, int type)
@@ -4799,8 +4812,9 @@ static int get_tier_idx(struct lruvec *lruvec, int type)
 
 static int get_type_to_scan(struct lruvec *lruvec, struct scan_control *sc, int swappiness)
 {
-	struct ctrl_pos sp, pv;
-
+	struct lru_gen_folio *lrugen = &lruvec->lrugen;
+	unsigned long anon_scanned, file_scanned;
+ 
 	if (swappiness == MIN_SWAPPINESS)
 		return LRU_GEN_FILE;
 
@@ -4816,14 +4830,15 @@ static int get_type_to_scan(struct lruvec *lruvec, struct scan_control *sc, int
 
 	if (swappiness >= MAX_SWAPPINESS)
 		return LRU_GEN_ANON;
-	/*
-	 * Compare the sum of all tiers of anon with that of file to determine
-	 * which type to scan.
-	 */
-	read_ctrl_pos(lruvec, LRU_GEN_ANON, MAX_NR_TIERS, swappiness, &sp);
-	read_ctrl_pos(lruvec, LRU_GEN_FILE, MAX_NR_TIERS, MAX_SWAPPINESS - swappiness, &pv);
 
-	return positive_ctrl_err(&sp, &pv);
+	anon_scanned = lrugen->nr_scan[LRU_GEN_ANON] + 1;
+	file_scanned = lrugen->nr_scan[LRU_GEN_FILE] + 1;
+
+	if (anon_scanned * (MAX_SWAPPINESS - swappiness) > file_scanned * swappiness)
+		return LRU_GEN_FILE;
+
+	return LRU_GEN_ANON;
+
 }
 
 static int isolate_folios(unsigned long nr_to_scan, struct lruvec *lruvec,
@@ -4873,7 +4888,8 @@ static int evict_folios(unsigned long nr_to_scan, struct lruvec *lruvec,
 
 	scanned += try_to_inc_min_seq(lruvec, swappiness);
 
-	if (evictable_min_seq(lrugen->min_seq, swappiness) + MIN_NR_GENS > lrugen->max_seq)
+	if (evictable_min_seq(lrugen->min_seq, swappiness) + MIN_NR_GENS >
+	    min(lrugen->max_seq[LRU_GEN_ANON], lrugen->max_seq[LRU_GEN_FILE]))
 		scanned = 0;
 
 	spin_unlock_irq(&lruvec->lru_lock);
@@ -4940,23 +4956,26 @@ static int evict_folios(unsigned long nr_to_scan, struct lruvec *lruvec,
 	return scanned;
 }
 
-static bool should_run_aging(struct lruvec *lruvec, unsigned long max_seq,
+static bool should_run_aging(struct lruvec *lruvec, unsigned long max_seq[],
 			     int swappiness, unsigned long *nr_to_scan)
 {
 	int gen, type, zone;
 	unsigned long size = 0;
+	bool need_aging = false;
 	struct lru_gen_folio *lrugen = &lruvec->lrugen;
 	DEFINE_MIN_SEQ(lruvec);
 
 	*nr_to_scan = 0;
 	/* have to run aging, since eviction is not possible anymore */
-	if (evictable_min_seq(min_seq, swappiness) + MIN_NR_GENS > max_seq)
-		return true;
+	for_each_evictable_type(type, swappiness) {
+		if (min_seq[type] + MIN_NR_GENS > max_seq[type])
+			return true;
+	}
 
 	for_each_evictable_type(type, swappiness) {
 		unsigned long seq;
 
-		for (seq = min_seq[type]; seq <= max_seq; seq++) {
+		for (seq = min_seq[type]; seq <= max_seq[type]; seq++) {
 			gen = lru_gen_from_seq(seq);
 
 			for (zone = 0; zone < MAX_NR_ZONES; zone++)
@@ -4966,7 +4985,11 @@ static bool should_run_aging(struct lruvec *lruvec, unsigned long max_seq,
 
 	*nr_to_scan = size;
 	/* better to run aging even though eviction is still possible */
-	return evictable_min_seq(min_seq, swappiness) + MIN_NR_GENS == max_seq;
+	for_each_evictable_type(type, swappiness) {
+		if (min_seq[type] + MIN_NR_GENS == max_seq[type])
+			need_aging = true;
+	}
+	return need_aging;
 }
 
 /*
@@ -4997,7 +5020,16 @@ static long get_nr_to_scan(struct lruvec *lruvec, struct scan_control *sc, int s
 		return nr_to_scan >> sc->priority;
 
 	/* stop scanning this lruvec as it's low on cold folios */
-	return try_to_inc_max_seq(lruvec, max_seq, swappiness, false) ? -1 : 0;
+	{
+		bool aged = false;
+		int type;
+
+		for_each_evictable_type(type, swappiness) {
+			if (try_to_inc_max_seq(lruvec, max_seq[type], type, swappiness, false))
+				aged = true;
+		}
+		return aged ? -1 : 0;
+	}
 }
 
 static bool should_abort_scan(struct lruvec *lruvec, struct scan_control *sc)
@@ -5524,7 +5556,7 @@ static void *lru_gen_seq_next(struct seq_file *m, void *v, loff_t *pos)
 }
 
 static void lru_gen_seq_show_full(struct seq_file *m, struct lruvec *lruvec,
-				  unsigned long max_seq, unsigned long *min_seq,
+				  unsigned long max_seq[], unsigned long *min_seq,
 				  unsigned long seq)
 {
 	int i;
@@ -5539,7 +5571,7 @@ static void lru_gen_seq_show_full(struct seq_file *m, struct lruvec *lruvec,
 			const char *s = "xxx";
 			unsigned long n[3] = {};
 
-			if (seq == max_seq) {
+			if (seq == max_seq[type]) {
 				s = "RTx";
 				n[0] = READ_ONCE(lrugen->avg_refaulted[type][tier]);
 				n[1] = READ_ONCE(lrugen->avg_total[type][tier]);
@@ -5564,10 +5596,12 @@ static void lru_gen_seq_show_full(struct seq_file *m, struct lruvec *lruvec,
 		const char *s = "xxxx";
 		unsigned long n = 0;
 
-		if (seq == max_seq && NR_HIST_GENS == 1) {
+		if (seq == max(max_seq[LRU_GEN_ANON], max_seq[LRU_GEN_FILE]) &&
+		    NR_HIST_GENS == 1) {
 			s = "TYFA";
 			n = READ_ONCE(mm_state->stats[hist][i]);
-		} else if (seq != max_seq && NR_HIST_GENS > 1) {
+		} else if (seq != max(max_seq[LRU_GEN_ANON], max_seq[LRU_GEN_FILE]) &&
+			   NR_HIST_GENS > 1) {
 			s = "tyfa";
 			n = READ_ONCE(mm_state->stats[hist][i]);
 		}
@@ -5580,60 +5614,68 @@ static void lru_gen_seq_show_full(struct seq_file *m, struct lruvec *lruvec,
 /* see Documentation/admin-guide/mm/multigen_lru.rst for details */
 static int lru_gen_seq_show(struct seq_file *m, void *v)
 {
-	unsigned long seq;
-	bool full = debugfs_get_aux_num(m->file);
-	struct lruvec *lruvec = v;
-	struct lru_gen_folio *lrugen = &lruvec->lrugen;
-	int nid = lruvec_pgdat(lruvec)->node_id;
-	struct mem_cgroup *memcg = lruvec_memcg(lruvec);
-	DEFINE_MAX_SEQ(lruvec);
-	DEFINE_MIN_SEQ(lruvec);
-
-	if (nid == first_memory_node) {
-		const char *path = memcg ? m->private : "";
-
+    unsigned long seq;
+    bool full = debugfs_get_aux_num(m->file);
+    struct lruvec *lruvec = v;
+    struct lru_gen_folio *lrugen = &lruvec->lrugen;
+    int nid = lruvec_pgdat(lruvec)->node_id;
+    struct mem_cgroup *memcg = lruvec_memcg(lruvec);
+    DEFINE_MAX_SEQ(lruvec);
+    DEFINE_MIN_SEQ(lruvec);
+    if (nid == first_memory_node) {
+        const char *path = memcg ? m->private : "";
 #ifdef CONFIG_MEMCG
-		if (memcg)
-			cgroup_path(memcg->css.cgroup, m->private, PATH_MAX);
+        if (memcg)
+            cgroup_path(memcg->css.cgroup, m->private, PATH_MAX);
 #endif
-		seq_printf(m, "memcg %5hu %s\n", mem_cgroup_id(memcg), path);
-	}
-
-	seq_printf(m, " node %5d\n", nid);
-
-	if (!full)
-		seq = evictable_min_seq(min_seq, MAX_SWAPPINESS / 2);
-	else if (max_seq >= MAX_NR_GENS)
-		seq = max_seq - MAX_NR_GENS + 1;
-	else
-		seq = 0;
-
-	for (; seq <= max_seq; seq++) {
-		int type, zone;
-		int gen = lru_gen_from_seq(seq);
-		unsigned long birth = READ_ONCE(lruvec->lrugen.timestamps[gen]);
-
-		seq_printf(m, " %10lu %10u", seq, jiffies_to_msecs(jiffies - birth));
-
-		for (type = 0; type < ANON_AND_FILE; type++) {
-			unsigned long size = 0;
-			char mark = full && seq < min_seq[type] ? 'x' : ' ';
-
-			for (zone = 0; zone < MAX_NR_ZONES; zone++)
-				size += max(READ_ONCE(lrugen->nr_pages[gen][type][zone]), 0L);
-
-			seq_printf(m, " %10lu%c", size, mark);
-		}
-
-		seq_putc(m, '\n');
-
-		if (full)
-			lru_gen_seq_show_full(m, lruvec, max_seq, min_seq, seq);
-	}
-
-	return 0;
+        seq_printf(m, "memcg %5hu %s\n", mem_cgroup_id(memcg), path);
+    }
+    seq_printf(m, " node %5d\n", nid);
+    {
+        unsigned long max_seq_val = max(max_seq[LRU_GEN_ANON], max_seq[LRU_GEN_FILE]);
+        if (!full)
+            seq = evictable_min_seq(min_seq, MAX_SWAPPINESS / 2);
+        else if (max_seq_val >= MAX_NR_GENS)
+            seq = max_seq_val - MAX_NR_GENS + 1;
+        else
+            seq = 0;
+        for (; seq <= max_seq_val; seq++) {
+            int type, zone;
+            int gen = lru_gen_from_seq(seq);
+            seq_printf(m, " %10lu", seq);
+            /* show the older birth time among evictable types */
+            {
+                unsigned long birth = jiffies;
+                int t;
+                for (t = 0; t < ANON_AND_FILE; t++) {
+                    unsigned long ts = READ_ONCE(lruvec->lrugen.timestamps[t][gen]);
+                    if (time_before(ts, birth))
+                        birth = ts;
+                }
+                seq_printf(m, " %10u", jiffies_to_msecs(jiffies - birth));
+            }
+            for (type = 0; type < ANON_AND_FILE; type++) {
+                unsigned long size = 0;
+                char mark = ' ';
+                if (full) {
+                    if (seq < min_seq[type])
+                        mark = 'x';
+                    else if (seq > max_seq[type])
+                        mark = '-';
+                }
+                for (zone = 0; zone < MAX_NR_ZONES; zone++)
+                    size += max(READ_ONCE(lrugen->nr_pages[gen][type][zone]), 0L);
+                seq_printf(m, " %10lu%c", size, mark);
+            }
+            seq_putc(m, '\n');
+            if (full)
+                lru_gen_seq_show_full(m, lruvec, max_seq, min_seq, seq);
+        }
+    }
+    return 0;
 }
 
+
 static const struct seq_operations lru_gen_seq_ops = {
 	.start = lru_gen_seq_start,
 	.stop = lru_gen_seq_stop,
@@ -5644,21 +5686,38 @@ static const struct seq_operations lru_gen_seq_ops = {
 static int run_aging(struct lruvec *lruvec, unsigned long seq,
 		     int swappiness, bool force_scan)
 {
+	int type;
+	bool success = false;
 	DEFINE_MAX_SEQ(lruvec);
 
-	if (seq > max_seq)
-		return -EINVAL;
+	
+	for_each_evictable_type(type, swappiness) {
+		if (seq > max_seq[type])
+			return -EINVAL;
+	}
 
-	return try_to_inc_max_seq(lruvec, max_seq, swappiness, force_scan) ? 0 : -EEXIST;
+	for_each_evictable_type(type, swappiness) {
+		if (seq == max_seq[type]) {
+			if (try_to_inc_max_seq(lruvec, max_seq[type], type,
+					       swappiness, force_scan))
+				success = true;
+		}
+	}
+
+	return success ? 0 : -EEXIST;
 }
 
 static int run_eviction(struct lruvec *lruvec, unsigned long seq, struct scan_control *sc,
 			int swappiness, unsigned long nr_to_reclaim)
 {
+	int type;
 	DEFINE_MAX_SEQ(lruvec);
 
-	if (seq + MIN_NR_GENS > max_seq)
-		return -EINVAL;
+
+	for_each_evictable_type(type, swappiness) {
+		if (seq + MIN_NR_GENS > max_seq[type])
+			return -EINVAL;
+	}
 
 	sc->nr_reclaimed = 0;
 
@@ -5857,17 +5916,21 @@ void lru_gen_init_lruvec(struct lruvec *lruvec)
 	struct lru_gen_folio *lrugen = &lruvec->lrugen;
 	struct lru_gen_mm_state *mm_state = get_mm_state(lruvec);
 
-	lrugen->max_seq = MIN_NR_GENS + 1;
+	for (type = 0; type < ANON_AND_FILE; type++) {
+		lrugen->max_seq[type] = MIN_NR_GENS + 1;
+		for (i = 0; i <= MIN_NR_GENS + 1; i++)
+			lrugen->timestamps[type][i] = jiffies;
+	}
 	lrugen->enabled = lru_gen_enabled();
 
-	for (i = 0; i <= MIN_NR_GENS + 1; i++)
-		lrugen->timestamps[i] = jiffies;
 
 	for_each_gen_type_zone(gen, type, zone)
 		INIT_LIST_HEAD(&lrugen->folios[gen][type][zone]);
 
-	if (mm_state)
-		mm_state->seq = MIN_NR_GENS;
+	if (mm_state) {
+		mm_state->seq[LRU_GEN_ANON] = MIN_NR_GENS;
+		mm_state->seq[LRU_GEN_FILE] = MIN_NR_GENS;
+	}
 }
 
 #ifdef CONFIG_MEMCG
diff --git a/mm/workingset.c b/mm/workingset.c
index 68a76a911..e98c31128 100644
--- a/mm/workingset.c
+++ b/mm/workingset.c
@@ -262,7 +262,8 @@ static void *lru_gen_eviction(struct folio *folio)
  * Fills in @lruvec, @token, @workingset with the values unpacked from shadow.
  */
 static bool lru_gen_test_recent(void *shadow, struct lruvec **lruvec,
-				unsigned long *token, bool *workingset)
+				unsigned long *token, bool *workingset,
+				int type)
 {
 	int memcg_id;
 	unsigned long max_seq;
@@ -274,7 +275,7 @@ static bool lru_gen_test_recent(void *shadow, struct lruvec **lruvec,
 	memcg = mem_cgroup_from_id(memcg_id);
 	*lruvec = mem_cgroup_lruvec(memcg, pgdat);
 
-	max_seq = READ_ONCE((*lruvec)->lrugen.max_seq);
+	max_seq = READ_ONCE((*lruvec)->lrugen.max_seq[type]);
 	max_seq &= EVICTION_MASK >> LRU_REFS_WIDTH;
 
 	return abs_diff(max_seq, *token >> LRU_REFS_WIDTH) < MAX_NR_GENS;
@@ -293,7 +294,7 @@ static void lru_gen_refault(struct folio *folio, void *shadow)
 
 	rcu_read_lock();
 
-	recent = lru_gen_test_recent(shadow, &lruvec, &token, &workingset);
+	recent = lru_gen_test_recent(shadow, &lruvec, &token, &workingset,type);
 	if (lruvec != folio_lruvec(folio))
 		goto unlock;
 
@@ -431,7 +432,7 @@ bool workingset_test_recent(void *shadow, bool file, bool *workingset,
 		bool recent;
 
 		rcu_read_lock();
-		recent = lru_gen_test_recent(shadow, &eviction_lruvec, &eviction, workingset);
+		recent = lru_gen_test_recent(shadow, &eviction_lruvec, &eviction, workingset,file);
 		rcu_read_unlock();
 		return recent;
 	}

